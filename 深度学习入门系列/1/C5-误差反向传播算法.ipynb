{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "数值微分虽然简单，也容易实现，但缺点是计算上比较费时间。\n",
    "本章我们将学习一个能够高效计算权重参数的梯度的方法——误差反向传播法。\n",
    "采用计算图法\n",
    "如果正向传播时的输入值小于等于0，则反向传播的值为0。因此，反向传播中会使用正向传播时保存的 mask，将从上游传来的 dout的mask中的元素为True的地方设为0。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9841e6891a4ba66"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-02T05:54:47.252958800Z",
     "start_time": "2023-11-02T05:54:47.240948400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    def forward(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        \n",
    "        return  out\n",
    "    def backward(self,dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy\n",
    "    \n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    def forward(self,x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "print(price) # 220\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "print(dapple, dapple_num, dtax) # 2.2 110 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T05:54:37.140936500Z",
     "start_time": "2023-11-02T05:54:37.137933100Z"
    }
   },
   "id": "f556f5cfc2d1d599"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num) #(1)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) #(2)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3)\n",
    "price = mul_tax_layer.forward(all_price, tax) #(4)\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice) #(4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) #(3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price) #(2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)\n",
    "print(price) # 715\n",
    "print(dapple_num, dapple, dorange, dorange_num, dtax) # 110 2.2 3.3 165 650"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T05:54:48.605057Z",
     "start_time": "2023-11-02T05:54:48.599758300Z"
    }
   },
   "id": "bd9d5857cd355382"
  },
  {
   "cell_type": "markdown",
   "source": [
    "对 sigmoid 分解为$\\times$ -1, exp, +1, 取倒数四个步骤分别计算反向传播算法\n",
    "从后往前看：\n",
    "$\\frac{\\partial y}{\\partial x} = -\\frac{1}{x^2} = -y^2$\n",
    "....\n",
    "$\\begin{aligned}\n",
    "\\begin{aligned}\\frac{\\partial L}{\\partial y}y^2\\exp(-x)\\end{aligned}& =\\frac{\\partial L}{\\partial y}\\frac1{(1+\\exp(-x))^2}\\exp(-x)  \\\\\n",
    "&=\\frac{\\partial L}{\\partial y}\\frac1{1+\\exp(-x)}\\frac{\\exp(-x)}{1+\\exp(-x)} \\\\\n",
    "&=\\frac{\\partial L}{\\partial y}y(1-y)\n",
    "\\end{aligned}$\n",
    "图示见notion\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ae3f54869990fb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    def forward(self, x):\n",
    "        out = 1/(1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ee5a3d24376e8ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.6 Affine\n",
    "Affine层\n",
    "(2,) 当作1行2列看\n",
    "$X(2,) \\cdot W(2,3) = O(3,)$ \n",
    "\n",
    "$\\begin{aligned}\\frac{\\partial L}{\\partial\\boldsymbol{X}}&=\\frac{\\partial L}{\\partial\\boldsymbol{Y}}\\cdot\\boldsymbol{W}^\\mathrm{T}\\\\\\frac{\\partial L}{\\partial\\boldsymbol{W}}&=\\boldsymbol{X}^\\mathrm{T}\\cdot\\frac{\\partial L}{\\partial\\boldsymbol{Y}}\\end{aligned}$\n",
    "\n",
    "5.6.2 批版本的Affine层\n",
    "$\\begin{gathered}\n",
    "\\begin{aligned}\\frac{\\partial L}{\\partial X}=\\frac{\\partial L}{\\partial Y}\\cdot W^\\mathrm{T}\\end{aligned} \\\\\n",
    "\\begin{matrix}(N,2)&(N,3)&(3,2)\\end{matrix} \\\\\n",
    "\\frac{\\partial L}{\\partial W} =X^{\\mathrm{T}}\\cdot\\frac{\\partial L}{\\partial Y} \\\\\n",
    "(2,3) (2,N)(N,3) \n",
    "\\end{gathered}$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82d7f39d23db1b23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    def forward(self,x):\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        # 这行代码的目的是将输入数据 x 调整为一个二维数组，其中第一个维度保持与原始数据相同，而第二个维度将被拉平为一维。这通常在神经网络的层中使用，以便在进行仿射变换（矩阵乘法）时适应权重矩阵的维度。\n",
    "        self.x = x\n",
    "        \n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T ,dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        # 在神经网络的反向传播过程中，梯度的形状需要与前向传播中相应的输入数据的形状保持一致，以确保正确的梯度传递\n",
    "        return dx\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da828995594ada5d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1576f7b3098cc74a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    def backward(self, dout = 1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a7bbb9c5acff663"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
